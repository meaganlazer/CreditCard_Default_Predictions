{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Classification Modeling\n",
    "The goal of this week's assessment is to find the model which best predicts whether a person will default on their loan. In doing so, we want to utilize all of the different tools we have learned over the course: data cleaning, EDA, feature engineering/transformation, feature selection, hyperparameter tuning, and model evaluation. \n",
    "\n",
    "Dataset: The dataset comes customers default payments in Taiwan. More information about the dataset and columns are found in the link below.\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients#\n",
    "\n",
    "\n",
    "You will fit three different models (KNN, Logistic Regression, and Decision Tree Classifier) and use gridsearch to find the best hyperparameters for those models. Then you will compare the performance of those three models on a test set to find the best one.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process/Expectations\n",
    "\n",
    "#### You will be working in pairs for this assessment; please have ONE notebook and be prepared to explain how you worked in your pair.\n",
    "1. Clean up your data set so that you can do EDA. This includes handling null values, categorical variables, removing unimportant columns, and removing outliers.\n",
    "2. Perform EDA to identify opportunities to create new features.\n",
    "    - [Great Example of EDA for classification](https://www.kaggle.com/stephaniestallworth/titanic-eda-classification-end-to-end) \n",
    "    - [Using Pairplots with Classification](https://towardsdatascience.com/visualizing-data-with-pair-plots-in-python-f228cf529166)\n",
    "3. Create polynomial and/or interaction features. You must also create at least 2 new features that are not interactions or polynomial transformations. For example, you can create a new dummy variable that based on the value of a continuous variable (billamount6 >2000) or take the average of some past amounts.\n",
    "4. Perform some feature selction. This can happen beforehand using F-scores, or you can do it as part of your model building process by looking at the weights of your regularized logistic regression or feature importance of your decision tree.  \n",
    "5. You must fit each of the three models to your data and tune at least 1 hyperparameter per model. \n",
    "6. After identifying the best hyperparameters for each model, fit those models to the test set and identify the best model overall using the evaluation metric of your choice.\n",
    "7. Present your best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "from math import exp\n",
    "from scipy.stats import norm\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import itertools\n",
    "import warnings\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier , GradientBoostingClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import make_scorer, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default payment next month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2873</td>\n",
       "      <td>350000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>466</td>\n",
       "      <td>466</td>\n",
       "      <td>316</td>\n",
       "      <td>316</td>\n",
       "      <td>316</td>\n",
       "      <td>466</td>\n",
       "      <td>466</td>\n",
       "      <td>316</td>\n",
       "      <td>316</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3598</td>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>13026</td>\n",
       "      <td>13268</td>\n",
       "      <td>13497</td>\n",
       "      <td>5500</td>\n",
       "      <td>0</td>\n",
       "      <td>580</td>\n",
       "      <td>600</td>\n",
       "      <td>600</td>\n",
       "      <td>600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>27623</td>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>4800</td>\n",
       "      <td>9810</td>\n",
       "      <td>660</td>\n",
       "      <td>2548</td>\n",
       "      <td>2321</td>\n",
       "      <td>4800</td>\n",
       "      <td>9810</td>\n",
       "      <td>660</td>\n",
       "      <td>2980</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6874</td>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>13784</td>\n",
       "      <td>13420</td>\n",
       "      <td>13686</td>\n",
       "      <td>1508</td>\n",
       "      <td>1216</td>\n",
       "      <td>1116</td>\n",
       "      <td>0</td>\n",
       "      <td>490</td>\n",
       "      <td>658</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6444</td>\n",
       "      <td>110000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>108829</td>\n",
       "      <td>110557</td>\n",
       "      <td>106082</td>\n",
       "      <td>5400</td>\n",
       "      <td>5400</td>\n",
       "      <td>4100</td>\n",
       "      <td>4100</td>\n",
       "      <td>4100</td>\n",
       "      <td>4200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  \\\n",
       "0   2873     350000    1          1         2   37     -2     -2     -2   \n",
       "1   3598      50000    2          2         1   37      2      2      2   \n",
       "2  27623      50000    2          1         2   23     -1     -1     -1   \n",
       "3   6874      20000    1          3         1   56      0      0      0   \n",
       "4   6444     110000    2          2         2   32      0      0      0   \n",
       "\n",
       "   PAY_4  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
       "0     -2  ...        466        466        316       316       316       466   \n",
       "1      0  ...      13026      13268      13497      5500         0       580   \n",
       "2     -1  ...       4800       9810        660      2548      2321      4800   \n",
       "3      0  ...      13784      13420      13686      1508      1216      1116   \n",
       "4      0  ...     108829     110557     106082      5400      5400      4100   \n",
       "\n",
       "   PAY_AMT4  PAY_AMT5  PAY_AMT6  default payment next month  \n",
       "0       466       316       316                           0  \n",
       "1       600       600       600                           0  \n",
       "2      9810       660      2980                           0  \n",
       "3         0       490       658                           0  \n",
       "4      4100      4100      4200                           0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('student_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = ['ID'], inplace = True)\n",
    "df.rename(columns = {'default payment next month':'DEFAULT'}, inplace = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.boxplot('LIMIT_BAL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['LIMIT_BAL']>900000]\n",
    "df.drop(index=[13774], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.boxplot(df,figsize=(8,8))\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "education_dummies = pd.get_dummies(df['EDUCATION'], prefix='education')\n",
    "marriage_dummies = pd.get_dummies(df['MARRIAGE'], prefix='marriage')\n",
    "df = pd.concat([df, education_dummies, marriage_dummies], axis=1)\n",
    "df.drop(columns = ['EDUCATION','MARRIAGE'], inplace = True)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = ['EDUCATION','MARRIAGE'], inplace = True)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corrmat = df[['DEFAULT','LIMIT_BAL', 'AGE','SEX', 'education_0', 'education_1', 'education_2',\n",
    "       'education_3', 'education_4', 'education_5', 'education_6',\n",
    "       'marriage_0', 'marriage_1', 'marriage_2', 'marriage_3']].corr()\n",
    "\n",
    "sns.set(font_scale=1)\n",
    "fig,ax= plt.subplots()\n",
    "fig.set_size_inches(10,10)\n",
    "plt.tight_layout()\n",
    "sns.heatmap(corrmat,square=True,annot=True, cbar = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat = df[['DEFAULT','LIMIT_BAL', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6',\\\n",
    "              'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', \\\n",
    "              'BILL_AMT6', 'PAY_AMT1','PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5',\\\n",
    "              'PAY_AMT6']].corr()\n",
    "sns.set(font_scale=1)\n",
    "fig,ax= plt.subplots()\n",
    "fig.set_size_inches(10,10)\n",
    "plt.tight_layout()\n",
    "sns.heatmap(corrmat,square=True,annot=True, cbar = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"SEX\", data=df,hue=\"DEFAULT\", palette=\"muted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.PAY_0 = np.where(df.PAY_0 < 1 , 0, df.PAY_0)\n",
    "# df.PAY_0 = np.where(df.PAY_0 >=1 , 1, df.PAY_0)\n",
    "\n",
    "# df.PAY_2 = np.where(df.PAY_2 < 1 , 0, df.PAY_0)\n",
    "# df.PAY_2 = np.where(df.PAY_2 >=1 , 1, df.PAY_0)\n",
    "\n",
    "# df.PAY_3 = np.where(df.PAY_3 < 1 , 0, df.PAY_0)\n",
    "# df.PAY_3 = np.where(df.PAY_3 >=1 , 1, df.PAY_0)\n",
    "\n",
    "# df.PAY_4 = np.where(df.PAY_4 < 1 , 0, df.PAY_0)\n",
    "# df.PAY_4 = np.where(df.PAY_4 >=1 , 1, df.PAY_0)\n",
    "\n",
    "# df.PAY_5 = np.where(df.PAY_5 < 1 , 0, df.PAY_0)\n",
    "# df.PAY_5 = np.where(df.PAY_5 >=1 , 1, df.PAY_0)\n",
    "\n",
    "# df.PAY_6 = np.where(df.PAY_6 < 1 , 0, df.PAY_0)\n",
    "# df.PAY_6 = np.where(df.PAY_6 >=1 , 1, df.PAY_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['DEFAULT'],axis=1)\n",
    "y = df['DEFAULT']\n",
    "\n",
    "X.corrwith(df['DEFAULT']).plot.bar(\n",
    "        figsize = (20, 10), title = \"Correlation with Default\", fontsize = 20,\n",
    "        rot = 90, grid = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recursive feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=df[['LIMIT_BAL', 'SEX', 'AGE', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5',\n",
    "       'PAY_6', 'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4',\n",
    "       'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3',\n",
    "       'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6', 'education_0',\n",
    "       'education_1', 'education_2', 'education_3', 'education_4',\n",
    "       'education_5', 'education_6', 'marriage_0', 'marriage_1', 'marriage_2',\n",
    "       'marriage_3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_train = X_train.min()\n",
    "# range_train = (X_train - min_train).max()\n",
    "# X_train_scaled = (X_train - min_train)/range_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_test = X_test.min()\n",
    "# range_test = (X_test - min_test).max()\n",
    "# X_test_scaled = (X_test - min_test)/range_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Fitting and Hyperparameter Tuning\n",
    "KNN, Logistic Regression, Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('DEFAULT', axis = 1)\n",
    "y = df['DEFAULT']\n",
    "feature_cols = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up testing and training sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create intercept term\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit model\n",
    "logit_model = sm.Logit(y, X)\n",
    "\n",
    "# Get results of the fit\n",
    "result = logit_model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(fit_intercept = False, C = 1e15, solver='liblinear')\n",
    "model_log = logreg.fit(X, y)\n",
    "model_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()  \n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)  \n",
    "X_test = scaler.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "print(knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make class predictions for the testing set\n",
    "y_pred_class = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate accuracy\n",
    "print('Accuracy:' + str(metrics.accuracy_score(y_test, y_pred_class)))\n",
    "print('F1:' + str(metrics.f1_score(y_test, y_pred_class)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model: XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['DEFAULT'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('DEFAULT', axis = 1)\n",
    "y = df['DEFAULT']\n",
    "feature_cols = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.concat([X_train,y_train], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndefault = training[training['DEFAULT']==0]\n",
    "default = training[training['DEFAULT']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsampled = resample(default,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=len(ndefault), # match number in majority class\n",
    "                          random_state=23) # reproducible results\n",
    "\n",
    "upsampled = pd.concat([ndefault, upsampled])\n",
    "upsampled['DEFAULT'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "upsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ndefault = df[df['DEFAULT']==0]\n",
    "# default = df[df['DEFAULT']==1]\n",
    "\n",
    "# upsampled = resample(default,\n",
    "#                           replace=True, # sample with replacement\n",
    "#                           n_samples=len(ndefault), # match number in majority class\n",
    "#                           random_state=23) # reproducible results\n",
    "\n",
    "# upsampled = pd.concat([ndefault, upsampled])\n",
    "# upsampled['DEFAULT'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = upsampled.drop('DEFAULT', axis = 1)\n",
    "y_train = upsampled['DEFAULT']\n",
    "feature_cols = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.XGBClassifier()\n",
    "xg_clf = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                           colsample_bytree = 0.3, \n",
    "                           subsample = 0.5,\n",
    "                           learning_rate = 0.1,\n",
    "                           max_depth = 4, \n",
    "                           alpha = 1, \n",
    "                           n_estimators = 10000)\n",
    "xg_clf.fit(X_train,y_train)\n",
    "preds = xg_clf.predict(X_test)\n",
    "\n",
    "test_f1 = f1_score(y_test, preds)\n",
    "test_acc = accuracy_score(y_test, preds)\n",
    "\n",
    "print(\"Accuracy: %f\" % (test_acc))\n",
    "print(\"F1: %f\" % (test_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('hold_out_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(columns = ['Unnamed: 0'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "education_dummies = pd.get_dummies(test['EDUCATION'], prefix='education')\n",
    "marriage_dummies = pd.get_dummies(test['MARRIAGE'], prefix='marriage')\n",
    "test = pd.concat([test, education_dummies, marriage_dummies], axis=1)\n",
    "test.drop(columns = ['EDUCATION','MARRIAGE'], inplace = True)\n",
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results=xg_clf.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results=pd.Series(final_results)\n",
    "final_results.to_csv('MR.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# with open('MandR_Pickle.pickle','wb') as f:\n",
    "#     pickle.dump(xg_clf, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes: clean-up code for the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fit_predict(model1, x_train, y_train, test):\n",
    "#     model.fit(x_train, y_train)\n",
    "#     predictions = model.predict(test)\n",
    "# print('Test Accuracy Score', accuracy_score(test, prediction))\n",
    "# print('F1 Score', f1_score(test, prediction))\n",
    "# return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
